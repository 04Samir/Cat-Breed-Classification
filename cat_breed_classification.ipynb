{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh4Qnj0_nktZ"
      },
      "source": [
        "# Cat Breed Classification Using Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5NCuLbtnkta"
      },
      "source": [
        "## 1. Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93WG0ciInkta"
      },
      "source": [
        "### 1.1. Definition of the Problem\n",
        "\n",
        "This project aims to build and train a deep learning model to classify images of cats into their respective breeds. The task is framed as a multi-class classification problem, where each image is assigned a single breed label. Using principles from **Topic 5: Deep Learning for Computer Vision**, the model will leverage transfer learning and advanced techniques to achieve high accuracy.\n",
        "\n",
        "The project also explores methods to optimise performance, including data augmentation, batch normalisation, and callbacks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgn435d-nktb"
      },
      "source": [
        "### 1.2. Dataset\n",
        "\n",
        "- **`data/raw/cats.csv`**\n",
        "  - A metadata file containing information about each image.\n",
        "- **`data/raw/images/{breeds}`**\n",
        "  - Contains subfolders named after each breed, with each subfolder holding the corresponding images of cats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3qIC2HCnktb"
      },
      "source": [
        "### 1.3. Workflow\n",
        "\n",
        "The workflow follows **Chollet's Universal Workflow for Deep Learning**:\n",
        "1. **Data Loading & Exploration:** Load and inspect the dataset.\n",
        "2. **Data Preprocessing:** Split the dataset, apply augmentation, and preprocess images.\n",
        "3. **Baseline Model:** Train a model using transfer learning with EfficientNet.\n",
        "4. **Advanced Techniques:** Enhance the model with batch normalisation, callbacks, and the Functional API.\n",
        "5. **Evaluation:** Test the model and visualise results with metrics and Grad-CAM.\n",
        "6. **Conclusion:** Summarise results and propose improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFyK2ytunktb"
      },
      "source": [
        "### 1.4. Advanced Techniques\n",
        "\n",
        "The following advanced techniques from **Topic 7** are applied:\n",
        "1. **Functional API:** To build a flexible and modular model.\n",
        "2. **Batch Normalisation:** For stable and efficient training.\n",
        "3. **Callbacks:** To monitor training with early stopping and learning rate scheduling.\n",
        "4. **Grad-CAM:** To interpret predictions by visualising key image regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRQqOlQBnktb"
      },
      "source": [
        "## 2. Data Loading & Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNNmAFu092Pp"
      },
      "source": [
        "### 2.1. Downloading the Dataset\n",
        "\n",
        "First we must download the dataset from Kaggle, ensure that you have a `kaggle.json` file uploaded to your Google Drive (if on Google Colab), otherwise store it here in the root directory.\n",
        "\n",
        "If the dataset is not already present in the environment, the notebook will:\n",
        "1. Resolve the `kaggle.json`.\n",
        "2. Configure the Kaggle API for authentication.\n",
        "3. Download and extract the dataset into the `data/raw` directory.\n",
        "\n",
        "This step ensures the dataset is available for exploration and preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXQtxGA2nohy",
        "outputId": "c53f9157-5f0c-4ce0-f35a-39652d6fc1eb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# Define Dataset & API Key Paths\n",
        "DATASET_DIR = pathlib.Path(\"data\")\n",
        "RAW_DIR = DATASET_DIR / \"raw\"\n",
        "KAGGLE_JSON_LOCAL = \"kaggle.json\"\n",
        "KAGGLE_JSON_DRIVE = \"/content/drive/MyDrive/kaggle.json\"\n",
        "\n",
        "# Function to Check Dataset Presence\n",
        "def is_dataset_present() -> bool:\n",
        "    if RAW_DIR.exists() and any(RAW_DIR.iterdir()):\n",
        "        print(\"Dataset Already Exists in `data/raw` - Skipping Download . . .\")\n",
        "        return True\n",
        "    print(\"Dataset Not Found!\")\n",
        "    return False\n",
        "\n",
        "# Function to Setup Kaggle Authentication\n",
        "def setup_kaggle_auth() -> bool:\n",
        "    if os.path.isfile(KAGGLE_JSON_LOCAL):\n",
        "        print(\"Found `kaggle.json` Locally!\")\n",
        "        os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "        os.system(f\"cp {KAGGLE_JSON_LOCAL} ~/.kaggle/\")\n",
        "        os.system(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
        "        return True\n",
        "\n",
        "    elif \"google.colab\" in sys.modules:\n",
        "        print(\"`kaggle.json` Not Found Locally - Checking Google Drive . . .\")\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        if os.path.isfile(KAGGLE_JSON_DRIVE):\n",
        "            print(\"Found `kaggle.json` in Google Drive!\")\n",
        "            os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "            os.system(f\"cp {KAGGLE_JSON_DRIVE} ~/.kaggle/\")\n",
        "            os.system(\"chmod 600 ~/.kaggle/kaggle.json\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"`kaggle.json` Not Found in Google Drive! Please Add it to Your Root Drive.\")\n",
        "            return False\n",
        "\n",
        "    else:\n",
        "        print(\"`kaggle.json` Not Found Locally & Not in a Colab Environment!\")\n",
        "        print(\"Please Add `kaggle.json` to the Current Directory.\")\n",
        "        return False\n",
        "\n",
        "# Function to Download & Extract Dataset\n",
        "def download_and_extract_dataset() -> None:\n",
        "    print(\"Downloading Dataset from Kaggle . . .\")\n",
        "    os.system(\"kaggle datasets download -d denispotapov/cat-breeds-dataset-cleared -p .\")\n",
        "    os.system(\"unzip -q cat-breeds-dataset-cleared.zip -d .\")\n",
        "    print(\"Dataset Downloaded & Extracted Successfully!\")\n",
        "\n",
        "# Function to Clean and Organize Dataset\n",
        "def organise_dataset() -> None:\n",
        "    # Rename 'dataset' to 'data'\n",
        "    dataset_dir = pathlib.Path(\"dataset\")\n",
        "    if dataset_dir.exists() and dataset_dir.is_dir():\n",
        "        dataset_dir.rename(\"data\")\n",
        "\n",
        "    # Move Files to 'data/raw'\n",
        "    os.makedirs(RAW_DIR, exist_ok=True)\n",
        "    for item in DATASET_DIR.iterdir():\n",
        "        if item.is_file() or item.is_dir() and item.name != \"raw\":\n",
        "            shutil.move(str(item), str(RAW_DIR))\n",
        "\n",
        "    # Move Files from 'data/raw/data' to 'data/raw'\n",
        "    nested_data_dir = RAW_DIR / \"data\"\n",
        "    if nested_data_dir.exists() and nested_data_dir.is_dir():\n",
        "        for item in nested_data_dir.iterdir():\n",
        "            shutil.move(str(item), str(RAW_DIR))\n",
        "        nested_data_dir.rmdir()  # Remove the now-empty 'data' folder\n",
        "\n",
        "    # Delete ZIP File\n",
        "    zip_path = pathlib.Path(\"cat-breeds-dataset-cleared.zip\")\n",
        "    if zip_path.exists():\n",
        "        zip_path.unlink()\n",
        "\n",
        "    print(\"Dataset Files Organized in `data/raw`!\")\n",
        "\n",
        "# Main Execution Flow\n",
        "if not is_dataset_present():  # Check if Dataset is Already Present\n",
        "    kaggle_auth = setup_kaggle_auth()  # Set-Up Kaggle Authentication\n",
        "    if kaggle_auth:\n",
        "        download_and_extract_dataset()\n",
        "        organise_dataset()  # Organize Files in `data/raw`\n",
        "    else:\n",
        "        print(\"Kaggle Authentication Failed - Dataset Cannot Be Downloaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-rTjZK5nkte"
      },
      "source": [
        "### 2.2. Exploring the Dataset\n",
        "\n",
        "To understand the dataset, we will:\n",
        "1. Analyse the class distribution of breeds to check for imbalances.\n",
        "2. Visualise a few sample images from different breeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmsbaCkknkte",
        "outputId": "c920a0e0-3d6a-4f70-cb0a-529830cec89e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Metadata\n",
        "csv_path = RAW_DIR / \"cats.csv\"\n",
        "cats_data = pd.read_csv(csv_path)\n",
        "\n",
        "# Check for Missing Values\n",
        "missing_values = cats_data.isnull().sum()\n",
        "print(\"Missing Values in the Dataset:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Get Unique Breeds and Their Counts\n",
        "breed_counts = cats_data['breed'].value_counts()\n",
        "print(\"\\nClass Distribution of Breeds:\")\n",
        "print(breed_counts)\n",
        "\n",
        "# Get the Number of Unique Breeds\n",
        "num_breeds = cats_data['breed'].nunique()\n",
        "print(f\"\\nNumber of Unique Breeds: {num_breeds}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4X0X-GUnkte"
      },
      "source": [
        "### 2.3. Visualising the Dataset\n",
        "\n",
        "We will display:\n",
        "1. A bar plot of the breed distribution to identify dominant or underrepresented classes.\n",
        "2. Randomly selected images from the dataset along with their breed labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2uzrw3Xdnkte",
        "outputId": "2e460b10-2ffe-4581-da21-4b170759d9c0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot Breed Distribution with Adjusted Margins and Readable Labels\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.barplot(x=breed_counts.values, y=breed_counts.index, color=\"blue\")  # Single color avoids warning\n",
        "plt.title('Class Distribution of Cat Breeds', fontsize=16)\n",
        "plt.xlabel('Count', fontsize=12)\n",
        "plt.ylabel('Breed', fontsize=12)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()  # Ensures the layout adjusts to avoid label overlap\n",
        "plt.show()\n",
        "\n",
        "# Visualise 6 Sample Images in a Grid\n",
        "IMAGE_DIR = RAW_DIR / \"images\"\n",
        "\n",
        "# Select the Most Common Breed\n",
        "sample_breed = breed_counts.index[0]\n",
        "all_images = os.listdir(os.path.join(IMAGE_DIR, sample_breed))\n",
        "\n",
        "# Randomly Select 6 Images\n",
        "random_images = random.sample(all_images, min(len(all_images), 6))  # Ensure no more than available images\n",
        "\n",
        "# Set Number of Rows and Columns\n",
        "cols = 3\n",
        "rows = 2\n",
        "\n",
        "# Adjust the Figure Size for Compact Display\n",
        "plt.figure(figsize=(4 * cols, 4 * rows))\n",
        "\n",
        "for i, img_file in enumerate(random_images):\n",
        "    img_path = os.path.join(IMAGE_DIR, sample_breed, img_file)\n",
        "    img = mpimg.imread(img_path)\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{sample_breed} {i+1}\", fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsjoh48Ba9xu"
      },
      "source": [
        "## 3. Data Pre-Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv7qIlv8a9xu"
      },
      "source": [
        "### 3.1. Cleaning the Dataset\n",
        "We will inspect the dataset for any missing or inconsistent values and handle them appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUqwEdIva9xu",
        "outputId": "9ed687ee-e3e0-49ff-fb42-9c62264ba106"
      },
      "outputs": [],
      "source": [
        "# Inspect Missing Values\n",
        "print(\"Missing Values Per Column:\")\n",
        "print(cats_data.isnull().sum())\n",
        "\n",
        "# Drop Rows with Missing Values\n",
        "cats_data = cats_data.dropna()\n",
        "print(f\"Dataset Size After Dropping Missing Values: {len(cats_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQe9HxUla9xu"
      },
      "source": [
        "### 3.2. Splitting the Dataset\n",
        "\n",
        "We dynamically split the dataset into `train`, `validation`, and `test` directories based on the existing subdirectories in `data/raw/images`. Each breed corresponds to a subdirectory, and the images are distributed into the three sets while maintaining class segregation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pyayOngsFrB",
        "outputId": "8df9b7c2-58db-4c2a-ce8c-e0f3addb760f"
      },
      "outputs": [],
      "source": [
        "# Set to Use a Fraction of Data\n",
        "USE_DATA_FRACTION = True\n",
        "\n",
        "# Define Paths\n",
        "SPLITS_DIR = DATASET_DIR / \"splits\"\n",
        "SPLITS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Check if Directories Already Exist\n",
        "if all((SPLITS_DIR / subset).exists() and any((SPLITS_DIR / subset).iterdir()) for subset in ['train', 'validation', 'test']):\n",
        "    print(\"Dataset Already Organised Into Train, Validation & Test Folders. Skipping Re-Organisation!\")\n",
        "else:\n",
        "    # Organise Dataset If Directories Are Missing or Empty\n",
        "    print(\"Organising Dataset Into Train, Validation & Test Folders . . .\")\n",
        "\n",
        "    # Iterate Over Breeds (Folders in IMAGE_DIR)\n",
        "    for breed_dir in IMAGE_DIR.iterdir():\n",
        "        if breed_dir.is_dir():  # Ensure Itâ€™s a Directory\n",
        "            breed = breed_dir.name\n",
        "            images = list(breed_dir.glob(\"*.jpg\"))\n",
        "\n",
        "            # Shuffle Images for Random Distribution\n",
        "            random.shuffle(images)\n",
        "\n",
        "            # Use Fraction of Data if Enabled\n",
        "            if USE_DATA_FRACTION:\n",
        "                images = images[:int(len(images) * 0.2)] # Use 20% of Data\n",
        "\n",
        "            # Split Data\n",
        "            train_split = int(len(images) * 0.64)\n",
        "            val_split = int(len(images) * 0.16)\n",
        "\n",
        "            train_images = images[:train_split]\n",
        "            val_images = images[train_split:train_split + val_split]\n",
        "            test_images = images[train_split + val_split:]\n",
        "\n",
        "            # Helper Function to Move Images\n",
        "            def move_images(image_list, subset):\n",
        "                subset_breed_dir = SPLITS_DIR / subset / breed\n",
        "                subset_breed_dir.mkdir(parents=True, exist_ok=True)\n",
        "                for img in image_list:\n",
        "                    shutil.copy(img, subset_breed_dir / img.name)\n",
        "\n",
        "            # Move Images to Appropriate Folders\n",
        "            move_images(train_images, \"train\")\n",
        "            move_images(val_images, \"validation\")\n",
        "            move_images(test_images, \"test\")\n",
        "\n",
        "    print(\"Dataset Re-Organised Successfully!\")\n",
        "    print(f\"Train Images: {len(list((SPLITS_DIR / 'train').rglob('*.jpg')))}\")\n",
        "    print(f\"Validation Images: {len(list((SPLITS_DIR / 'validation').rglob('*.jpg')))}\")\n",
        "    print(f\"Test Images: {len(list((SPLITS_DIR / 'test').rglob('*.jpg')))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvyG6X7esFrC"
      },
      "source": [
        "### 3.3. Transferring to Generators\n",
        "\n",
        "Data generators streamline image preprocessing for training, validation, and testing. They:\n",
        "1. **Rescale Pixel Values**: All pixel values are normalised to the `[0, 1]` range.\n",
        "2. **Apply Augmentation**: Augmentation is applied to the training dataset to enhance model generalisation. Transformations include:\n",
        "   - Random rotations\n",
        "   - Width and height shifts\n",
        "   - Zoom and shear\n",
        "   - Horizontal flipping\n",
        "3. **Load Data Dynamically**: Images and labels are dynamically loaded based on the directory structure in `SPLITS_DIR`. Labels are automatically assigned based on subdirectory names.\n",
        "\n",
        "The resulting generators handle data preparation seamlessly for model training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrltCpmHsFrC",
        "outputId": "62dd32c0-14ee-40ad-eb50-800f26a5981c"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define Data Generators\n",
        "print(\"Setting Up Data Generators . . .\")\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    SPLITS_DIR / 'train',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=64   ,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    SPLITS_DIR / 'validation',\n",
        "    target_size=(128, 128),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    SPLITS_DIR / 'test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Preserve Order for Evaluation\n",
        ")\n",
        "\n",
        "# Display Class Indices\n",
        "print(\"Class Indices Mapping (Label to Class):\")\n",
        "print(train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzUzzQnLsFrC"
      },
      "source": [
        "## 4. Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8g_gl5-sFrC"
      },
      "source": [
        "### 4.1. Configuring the Model\n",
        "\n",
        "In this step, we configure the deep learning model for cat breed classification. The process involves:\n",
        "\n",
        "1. **Defining the Architecture**:\n",
        "   - A pre-trained base model (e.g., EfficientNet or ResNet) is used as a feature extractor, leveraging knowledge from the ImageNet dataset.\n",
        "   - Custom layers are added for the 67-class classification task.\n",
        "   - Dropout is used for regularisation to prevent overfitting.\n",
        "   - The final output layer uses softmax activation to predict probabilities for all 67 classes.\n",
        "\n",
        "2. **Compiling the Model**:\n",
        "   - **Loss Function**: Categorical cross-entropy for multi-class classification.\n",
        "   - **Optimiser**: Adam for efficient optimisation.\n",
        "   - **Metrics**: Accuracy as the evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "n23Y_RVosFrC",
        "outputId": "b0ac3fd2-d9ff-451b-cea5-ea10e9a679d3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from pathlib import Path\n",
        "\n",
        "# Dynamically Calculate Number of Classes\n",
        "train_dir = SPLITS_DIR / 'train'\n",
        "num_classes = len(list(train_dir.iterdir()))  # Count Subdirectories in 'train'\n",
        "\n",
        "# Load Pre-Trained Base Model\n",
        "print(\"Loading Pre-Trained ResNet50 Model . . .\")\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',  # Pre-Trained On ImageNet\n",
        "    include_top=False,   # Exclude The Original Classification Head\n",
        "    input_shape=(128, 128, 3)  # Input Size For ResNet50\n",
        ")\n",
        "\n",
        "# Freeze The Base Model's Layers\n",
        "print(\"Freezing Base Model Layers . . .\")\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build The Model Architecture\n",
        "print(\"Building The Model Architecture . . .\")\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),  # Convert Feature Maps To A Single Vector\n",
        "    Dropout(0.5),              # Add Dropout For Regularisation\n",
        "    Dense(256, activation='relu'),  # Fully Connected Layer\n",
        "    Dropout(0.3),                   # Add Another Dropout Layer\n",
        "    Dense(num_classes, activation='softmax')  # Output Layer For Detected Classes\n",
        "])\n",
        "\n",
        "# Compile The Model\n",
        "print(\"Compiling The Model . . .\")\n",
        "model.compile(\n",
        "    optimizer='adam',  # Adam Optimiser\n",
        "    loss='categorical_crossentropy',  # Multi-Class Classification Loss\n",
        "    metrics=['accuracy']  # Evaluate Model Using Accuracy\n",
        ")\n",
        "\n",
        "# Display Model Summary\n",
        "print(\"Displaying Model Summary . . .\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3oOvkxksFrD"
      },
      "source": [
        "### 4.2. Training the Model\n",
        "\n",
        "The model is trained using the training and validation datasets. This step includes:\n",
        "1. **Data Generators**: Feeding data dynamically using `train_generator` and `validation_generator`.\n",
        "2. **Callbacks**:\n",
        "   - **Early Stopping**: Stops training if validation performance stops improving to prevent overfitting.\n",
        "   - **Learning Rate Reduction**: Reduces the learning rate when the validation accuracy plateaus.\n",
        "3. **Training Configuration**:\n",
        "   - Number of epochs and batch size are defined for efficient training.\n",
        "   - Validation data is evaluated after each epoch to monitor performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "rKxlf56CsFrD",
        "outputId": "da4ad4b0-3e2c-4245-d243-6ccbd0e46f51"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define Callbacks\n",
        "print(\"Setting Up Callbacks . . .\")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor Validation Loss\n",
        "    patience=8,          # Increase Patience for Deeper Models\n",
        "    restore_best_weights=True  # Restore Weights From Best Epoch\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor Validation Loss\n",
        "    factor=0.2,          # Reduce Learning Rate By Factor Of 0.2\n",
        "    patience=5,          # Trigger LR Reduction After 5 Epochs Without Improvement\n",
        "    min_lr=1e-6          # Set Minimum Learning Rate\n",
        ")\n",
        "\n",
        "# Adjust Training Parameters\n",
        "print(\"Starting Model Training . . .\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping, reduce_lr],\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Training Completed\n",
        "print(\"Model Training Completed.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
